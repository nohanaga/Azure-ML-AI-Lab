{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae7ce40177087e2e5a2b6614a12a99225d2de094"
   },
   "source": [
    "# Module2: Boston Housing with Linear Regression\n",
    "\n",
    "**ボストン市内の特定の地域の住宅価格を予測する回帰式を作成し、どのような地域だと価格が高くなりやすいのかを考察する。**\n",
    "\n",
    "データには以下の列が含まれています:\n",
    "* 'crim': 町ごとの一人当たりの犯罪率。\n",
    "* 'zn': 25,000平方フィートを超える区画に分類される住宅地の割合＝「広い家の割合」\n",
    "* 'indus': 町ごとの非小売業の面積の割合。\n",
    "* 'chas':チャールズ川のダミー変数（区画が川に接している場合は1、そうでない場合は0）＝「川の隣か」\n",
    "* 'nox': 「NOx濃度（0.1ppm単位）」＝一酸化窒素濃度（parts per 10 million単位）。この項目を目的変数とする場合もある\n",
    "* 'rm': 住戸あたりの平均部屋数。\n",
    "* 'age': 1940年より前に建てられた持ち家の割合＝「古い家の割合」\n",
    "* 'dis': ボストンの 5 つの雇用センターまでの距離の加重平均＝「主要施設への距離」\n",
    "* 'rad': 放射状の高速道路へのアクセス性の指標。\n",
    "* 'tax': 1万ドルあたりの全価値固定資産税の税率。\n",
    "* 'ptratio': 町別の生徒数と教師数の比率。\n",
    "* 'black':「1000(Bk - 0.63)」の二乗値。Bk＝「町ごとの黒人の割合」を指す\n",
    "* 'lstat': 「低所得者人口の割合」\n",
    "* 'medv': 「住宅価格」（1000ドル単位）の中央値。通常はこの数値が目的変数として使われる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "### 必要なライブラリをインストールする\n",
    "\n",
    "各セルを1つずつ実行して、必要なライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "互換性に関連するエラーは無視してください。 最後にこのメッセージが表示されている限り正常にインストールされています: Successfully installed seaborn もしくは Requirement already satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c45009768dc91bf48325ee04ab4b696521fc6220"
   },
   "source": [
    "## Let's Start !\n",
    "\n",
    "まず、環境を準備するために、いくつかのライブラリをインポートする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f144cb466fa1333d41b2356f588ebacba2cab79"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "#Warning を抑止\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abda91c61669228e1b29c2fcb4816e5fbf114c7a"
   },
   "outputs": [],
   "source": [
    "# データセットをpandasのDataFrameにインポートしてデータを見る\n",
    "BostonTrain = pd.read_csv(\"data/boston_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3844c8827b4e09d7e3a933976e04631cbdc53aef"
   },
   "source": [
    "**ここでは、Bostonのデータを見てみましょう。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24f0aae06fd2195aac00f39efb340e1230d5e255"
   },
   "outputs": [],
   "source": [
    "#DataFrameの先頭5行分を表示\n",
    "BostonTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7cb828d2c731ea59a70f6b0a6fb114815fb3bc7"
   },
   "outputs": [],
   "source": [
    "#pandas でデータの要約を表示\n",
    "BostonTrain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrameの行数、列数、各列の列名、各列に格納されるデータの型、メモリ使用量が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各列の要約統計量（平均、標準偏差など）を取得\n",
    "BostonTrain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac3e2547686ed620ba4749ef6f81635b1e5595a1"
   },
   "source": [
    "**目標はカラムについて考え、どのカラムがモデルを構築するのに関連性があるのかを発見することです。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欠損値の対応\n",
    "\n",
    "データをロードした後、データに欠落している値がないかどうかを確認することをお勧めします。isnull() を使用して、各機能の欠落値の数をカウントします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonTrain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbd32d564bbe45167243ce0b35d80781b18b94d4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#IDカラムは分析には関係ないので除去します\n",
    "BostonTrain.drop('ID', axis = 1, inplace=True)\n",
    "\n",
    "print(BostonTrain.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 外れ値の対応\n",
    "\n",
    "データ全体の傾向からかけ離れたデータのことを外れ値と呼びます。外れ値を含んだデータで機械学習を行うと、作成したモデルの予測性能が上がりにくくなってしまうことがあります。ただし、どの外れ値を除外するかは慎重に検討する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonTrain.plot.scatter('rm', 'medv', color=\"tab:blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rm の外れ値のindexを特定\n",
    "out_line1 = BostonTrain[(BostonTrain['rm'] > 8) & (BostonTrain['medv'] < 30)].index\n",
    "\n",
    "out_line2 = BostonTrain[(BostonTrain['rm'] < 5) & (BostonTrain['medv'] > 30)].index\n",
    "\n",
    "print(out_line1, out_line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop メソッドで指定index の行を削除\n",
    "BostonTrain = BostonTrain.drop(out_line1, axis = 0)\n",
    "BostonTrain = BostonTrain.drop(out_line2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BostonTrain.plot.scatter('rm', 'medv', color=\"tab:blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索的データ分析\n",
    "\n",
    "探索的データ分析は、モデルをトレーニングする前の非常に重要なステップです。このセクションでは、いくつかの視覚化を使用して、ターゲット変数と他の機能との関係を理解します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、ターゲット変数medv(住宅価格)の分布をプロットしましょう。seabornライブラリの distplot 関数を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.distplot(BostonTrain['medv'], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "medvの値は外れ値がほとんどなく正規分布していることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5bfd6e5b719921c25daf093fb43edee53978118b"
   },
   "outputs": [],
   "source": [
    "#住戸あたりの平均部屋数vs「住宅価格」（1000ドル単位）の中央値の散布図\n",
    "BostonTrain.plot.scatter('rm', 'medv', color=\"tab:blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "542c40d3f83ba619f9f2b189a147672ab696740c"
   },
   "source": [
    "このプロットでは、明らかに直線的なパターンを見ることができます。住戸あたりの平均部屋数が多いほど、住宅価格の中央値は高くなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(BostonTrain, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b98251ce12b200eedbaf510892a0d9b9899ca732"
   },
   "source": [
    "**では、すべての変数がどのように互いに関係しているかを見てみましょう。**\n",
    "\n",
    "変数間の線形関係を測定する相関行列を作成します。相関行列はcorr()、pandas データフレームライブラリの関数を使用して作成できます。seaborn ライブラリの heatmap 関数を使用して、相関行列をプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55c45be0eaeddb7a278e8d84c5468587b07b9333"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,8))\n",
    "sns.heatmap(BostonTrain.corr(), cmap = 'RdGy', annot=True, fmt=\"1.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8b88c3f535737db626cc4a73b0c1d76120a8df4"
   },
   "source": [
    "相関係数の範囲は-1から1です。値が1に近い場合は、2つの変数間に強い正の相関があることを意味します。-1に近い場合、変数には強い負の相関があります。\n",
    "\n",
    "このヒートマッププロットでは、ペアプロットよりも良い分析ができます。\n",
    "最後の行に注目してみましょう。\n",
    "\n",
    "- 赤/オレンジの色の濃淡：色が赤いほどX軸上にあり、medvが小さい。負の相関関係\n",
    "- 淡い色のとき：軸xとyにある変数は、何の関係もありません。相関性ゼロ\n",
    "- グレー/ブラックの濃淡の場合：X軸上の色が黒いほどmedvの値が高くなります。正の相関関係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Variation\n",
    "plt.figure(figsize=(20,5))\n",
    "features =['rm', 'lstat']\n",
    "target = BostonTrain['medv']\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1,len(features),i+1)\n",
    "    x = BostonTrain[col]\n",
    "    y=target\n",
    "    plt.scatter(x,y,marker='o')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('medv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rm変数は（0.72）であるターゲットmedvと強い相関関係があることがわかりました。 一方、lstatはmedvと高い負の相関があり、（-0.74）です。\n",
    "\n",
    "線形回帰モデルの特徴を選択する際の重要なポイントは、多重共線性（説明変数の間に強い相関関係が存在する場合）をチェックすることです。特徴量rad、taxの相関は0.91です。これらの特徴量ペアは、互いに強く相関しています。これはモデルに影響を与える可能性があります。-0.75の相関関係を持つ特徴量disとageについても同じことが言えます。これは、多重共線性を除外する必要があり、そのままにするとパラメーターの推定値が不安定になり、目的変数に対する説明変数の影響を評価することが非常に困難になります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "908c140881f1efd1fb83e0d77283629868408fb4"
   },
   "source": [
    "# 線形回帰モデルを訓練する\n",
    "\n",
    "**XとYの定義**\n",
    "\n",
    "X：説明変数、独立変数、特徴量として名前が付けられた変数。多群でも可。                       \n",
    "Y：応答または目的変数として名前が付けられた変数。1群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47d0ed5d507fe7a9a077acbf9c21b9c096a21df4"
   },
   "outputs": [],
   "source": [
    "X = BostonTrain[['rm']]\n",
    "y = BostonTrain['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#2変数のヒストグラムつきの散布図を作成する\n",
    "sns.jointplot(x=X['rm'], y='medv', data=BostonTrain, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e87bcf2fb6095a399423b93737f272861b85a24c"
   },
   "source": [
    "## データをトレーニングセットとテストセットに分割する\n",
    "\n",
    "データをトレーニングセットとテストセットに分割します。サンプルの70％でモデルをトレーニングし、残りの30％でテストします。これは、見えないデータに対するモデルのパフォーマンスを評価するために行います。データを分割するには train_test_split、scikit-learnライブラリが提供する関数を使用します。最後に、トレーニングとテストセットのサイズをprintして、分割が適切に行われたかどうかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fff1e5da66d42245e19fc0265eeefbb840812e3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train は全データセットの 70% を含む\n",
    "print(X_train.shape)\n",
    "# X_test は全データセットの 30% を含む\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰を適用する\n",
    "\n",
    "scikit-learn ライブラリの LinearRegression を使用して、トレーニングセットとテストセットの両方でモデルをトレーニングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af6124c5bfc498be6a185b8fcbcf4cd0a257580f"
   },
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6958dc7a17561e023f9e7a7bf8ccc720a9d46791"
   },
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(y_test,predictions, data=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル評価\n",
    "\n",
    "RMSEとR2スコアを使用してモデルを評価します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c77b4a60b955b84dbaa7a5d9355e80bd9708a9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R-squared:', metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSEを考える：我々は、このモデルの平均誤差がmedvでRMSE=6.1であると結論付けることができます。\n",
    "\n",
    "- 平均絶対誤差 (MAE, Mean Absolute Error) は、実際の値と予測値の絶対値を平均したものです。MAE が小さいほど誤差が少なく、予測モデルが正確に予測できていることを示し、MAE が大きいほど実際の値と予測値に誤差が大きく、予測モデルが正確に予測できていないといえます。\n",
    "\n",
    "$$\n",
    "    MAE=\\frac{1}{n}\\sum_{i=1}^{n}{|y_i-\\hat{y}_i|}   \n",
    "$$\n",
    "\n",
    "- 平均二乗誤差 (MSE, Mean Squared Error) とは、実際の値と予測値の絶対値の 2 乗を平均したものです。この為、MAE に比べて大きな誤差が存在するケースで、大きな値を示す特徴があります。MAE と同じく、値が大きいほど誤差の多いモデルと言えます。\n",
    "\n",
    "$$\n",
    "    MSE=\\frac{1}{n}\\sum_{i=1}^{n}{(y_i-\\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "\n",
    "- MSE の平方根を 二乗平均平方根誤差 (RMSE: Root Mean Squared Error) と呼びます。上記の MSE で、二乗したことの影響を平方根で補正したものです。RMSE は、RMSD (Root Mean Square Deviation) と呼ばれることもあります。\n",
    "\n",
    "$$\n",
    "    RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}{(y_i-\\hat{y}_i)^2}}\n",
    "$$\n",
    "\n",
    "- 決定係数 (R2, R-squared, coefficient of determination) は、モデルの当てはまりの良さを示す指標で、最も当てはまりの良い場合、1.0 となります (当てはまりの悪い場合、マイナスとなることもあります)。一般的に決定係数が 0.8 以上であれば、予測性能が高くてよい計算式といわれています。寄与率とも呼ばれます。観測値を $y_i$ ($\\mathit{i}$ = 1, 2, 3, ..., $\\mathit{n}$)、モデルから計算した計算値（予測値）を $\\hat{y}_i$、観測値の平均を $\\bar{y}_i$ とすると、\n",
    "\n",
    "$$\n",
    "    R^2=1-\\frac{\\sum_{i=1}^{n}{(y_i-\\hat{y}_i)^2}}{\\sum_{i=1}^{n}{(y_i-\\bar{y}_i)^2}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対応する二乗平均平方根誤差(RMSE)は約6.1となり、我々のモデルは実際の販売価格を約±$6,100の誤差の範囲で予測できることを表しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 残差の正規性の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f6a754fbfface772715da7af5903534f42f9031",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot((y_test-predictions),bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差の正規分布が多ければ多いほど良いモデルといえる。\n",
    "\n",
    "また、回帰分析の結果から残差を計算しQQ plotを描く。残差のプロットが直線状に乗っている場合は、正規分布していると見ていい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot((y_test-predictions), dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差プロットは、残差（目的変数の真値と予測値の差分）の分布を可視化したものです。線形モデルが目的変数を完璧に予測できる場合は残差は0となるので、予測精度の良い線形モデルの残差プロットは、0を中心にランダムにばらついたものになります。残差プロットに何かパターンが見られる場合は、線形モデルで説明しきれない情報があることが示唆されます。以下のコードは、残差プロットを描画します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions, predictions - y_test, color = 'blue')      # 残差をプロット \n",
    "plt.hlines(y = 0, xmin = -10, xmax = 50, color = 'black') # x軸に沿った直線をプロット\n",
    "plt.title('Residual Plot')                                # 図のタイトル\n",
    "plt.xlabel('Predicted Values')                            # x軸のラベル\n",
    "plt.ylabel('Residuals')                                   # y軸のラベル\n",
    "plt.grid()                                                # グリッド線を表示\n",
    "\n",
    "plt.show()                                               # 図の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## すべての特徴量を含めて回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BostonTrain[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat']]\n",
    "y = BostonTrain['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# X_train contains 70% of total dataset\n",
    "print(\"X_train size:\", X_train.shape, type(X_train), \"y_train size:\", y_train.shape, type(y_train))\n",
    "# X_test contains 30% of total dataset\n",
    "print(\"X_test size:\", X_test.shape, type(X_test), \"y_test size:\", y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(y_test,predictions, data=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R-squared:', metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('BostonPrediction.pkl', 'wb') as f:\n",
    "    pickle.dump(lm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BostonPrediction.pkl', 'rb') as f:\n",
    "    model2 = pickle.load(f)\n",
    "\n",
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 残差の正規性の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot((y_test-predictions),bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot((y_test-predictions), dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predictions, predictions - y_test, color = 'blue')      # 残差をプロット \n",
    "plt.hlines(y = 0, xmin = -10, xmax = 50, color = 'black') # x軸に沿った直線をプロット\n",
    "plt.title('Residual Plot')                                # 図のタイトル\n",
    "plt.xlabel('Predicted Values')                            # x軸のラベル\n",
    "plt.ylabel('Residuals')                                   # y軸のラベル\n",
    "plt.grid()                                                # グリッド線を表示\n",
    "\n",
    "plt.show()                                               # 図の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング\n",
    "\n",
    "元のデータに対して、2乗した値の列や3乗した値の列を生成して特徴量に加えることで特徴量表現が豊かになり、結果的に精度を高められることがあります。このようにして追加した特徴量を多項式特徴量といいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BostonTrain['rm2'] = BostonTrain['rm'] ** 2\n",
    "BostonTrain['rm3'] = BostonTrain['rm'] ** 3\n",
    "BostonTrain['rm4'] = BostonTrain['rm'] ** 4\n",
    "BostonTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BostonTrain[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat', 'rm2', 'rm3', 'rm4']]\n",
    "y = BostonTrain['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "predictions = lm.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R-squared:', metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、2つの列の対応する要素同士を掛けることで新たな特徴量を生成することもあります。このようにして追加した特徴量を、交互作用特徴量といいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonTrain['rm*lstat'] = BostonTrain['rm'] * BostonTrain['lstat']\n",
    "BostonTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BostonTrain[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
    "       'ptratio', 'black', 'lstat', 'rm2',  'rm*lstat']]\n",
    "y = BostonTrain['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "predictions = lm.predict(X_test)\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R-squared:', metrics.r2_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
